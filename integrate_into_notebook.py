import json
import pandas as pd
import numpy as np

def integrate_ml_enhancements_into_notebook():
    """
    Directly integrate ML enhancements into the existing Supply_Chain_Volatility_Intl.ipynb notebook
    """
    
    print("üöÄ INTEGRATING ML ENHANCEMENTS INTO EXISTING NOTEBOOK")
    print("=" * 60)
    
    # Read the existing notebook
    try:
        with open('Supply_Chain_Volatility_Intl.ipynb', 'r', encoding='utf-8') as f:
            notebook = json.load(f)
        print("‚úÖ Successfully loaded existing notebook")
    except Exception as e:
        print(f"‚ùå Error loading notebook: {e}")
        return False
    
    # Create the ML enhancement cell content
    ml_enhancement_cell = {
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "# ============================================================================\n",
            "# MACHINE LEARNING ENHANCEMENTS FOR SUPPLY CHAIN ANALYSIS\n",
            "# ============================================================================\n",
            "\n",
            "print(\"ü§ñ INTEGRATING ADVANCED ML CAPABILITIES\")\n",
            "print(\"=\" * 60)\n",
            "\n",
            "# Import required libraries for ML enhancements\n",
            "import pandas as pd\n",
            "import numpy as np\n",
            "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingRegressor, IsolationForest\n",
            "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
            "from sklearn.cluster import KMeans, DBSCAN\n",
            "from sklearn.decomposition import PCA\n",
            "from sklearn.model_selection import train_test_split, cross_val_score\n",
            "from sklearn.metrics import mean_squared_error, r2_score, classification_report\n",
            "import networkx as nx\n",
            "import matplotlib.pyplot as plt\n",
            "import seaborn as sns\n",
            "import plotly.express as px\n",
            "import plotly.graph_objects as go\n",
            "from plotly.subplots import make_subplots\n",
            "import warnings\n",
            "warnings.filterwarnings('ignore')\n",
            "\n",
            "# ============================================================================\n",
            "# 1. RISK SCORING SYSTEM IMPLEMENTATION\n",
            "# ============================================================================\n",
            "\n",
            "print(\"\\nüîç IMPLEMENTING COMPREHENSIVE RISK SCORING SYSTEM\")\n",
            "print(\"=\" * 60)\n",
            "\n",
            "class SupplyChainRiskScorer:\n",
            "    \"\"\"Comprehensive risk scoring system for international supply chains\"\"\"\n",
            "    \n",
            "    def __init__(self):\n",
            "        self.scaler = StandardScaler()\n",
            "        self.risk_models = {}\n",
            "        \n",
            "    def calculate_geographic_risk(self, df):\n",
            "        \"\"\"Calculate geographic concentration risk\"\"\"\n",
            "        # Calculate concentration risk (Herfindahl-Hirschman Index)\n",
            "        origin_concentration = df.groupby('fr_orig')['value_2023'].sum().pow(2).sum() / df['value_2023'].sum().pow(2)\n",
            "        dest_concentration = df.groupby('fr_dest')['value_2023'].sum().pow(2).sum() / df['value_2023'].sum().pow(2)\n",
            "        \n",
            "        geo_risk = (origin_concentration + dest_concentration) / 2\n",
            "        return pd.Series(geo_risk, index=df.index)\n",
            "    \n",
            "    def calculate_mode_risk(self, df):\n",
            "        \"\"\"Calculate transportation mode dependency risk\"\"\"\n",
            "        mode_features = df[['trade_type', 'tons_2023', 'tmiles_2023']].copy()\n",
            "        mode_features['tons_per_mile'] = df['tons_2023'] / (df['tmiles_2023'] + 1)\n",
            "        mode_features['value_per_mile'] = df['value_2023'] / (df['tmiles_2023'] + 1)\n",
            "        \n",
            "        if len(mode_features) > 10:\n",
            "            kmeans = KMeans(n_clusters=3, random_state=42)\n",
            "            mode_features['mode_cluster'] = kmeans.fit_predict(mode_features[['tons_per_mile', 'value_per_mile']])\n",
            "            cluster_risk = mode_features.groupby('mode_cluster')['tons_per_mile'].mean()\n",
            "            mode_features['mode_efficiency_risk'] = mode_features['mode_cluster'].map(cluster_risk)\n",
            "        else:\n",
            "            mode_features['mode_efficiency_risk'] = 0.5\n",
            "            \n",
            "        return mode_features['mode_efficiency_risk']\n",
            "    \n",
            "    def calculate_volatility_risk(self, df):\n",
            "        \"\"\"Calculate economic volatility risk\"\"\"\n",
            "        year_columns = [col for col in df.columns if 'tons_' in col and col != 'tons_2023']\n",
            "        \n",
            "        if len(year_columns) > 1:\n",
            "            tons_data = df[year_columns]\n",
            "            volatility = tons_data.std(axis=1) / (tons_data.mean(axis=1) + 1e-6)\n",
            "            volatility_risk = (volatility - volatility.min()) / (volatility.max() - volatility.min() + 1e-6)\n",
            "        else:\n",
            "            volatility_risk = pd.Series(0.5, index=df.index)\n",
            "            \n",
            "        return volatility_risk\n",
            "    \n",
            "    def calculate_infrastructure_risk(self, df):\n",
            "        \"\"\"Calculate infrastructure vulnerability risk\"\"\"\n",
            "        infra_features = df[['tons_2023', 'tmiles_2023', 'value_2023']].copy()\n",
            "        infra_features['tons_per_mile'] = df['tons_2023'] / (df['tmiles_2023'] + 1)\n",
            "        infra_features['value_density'] = df['value_2023'] / (df['tons_2023'] + 1)\n",
            "        \n",
            "        if len(infra_features) > 10:\n",
            "            iso_forest = IsolationForest(contamination=0.1, random_state=42)\n",
            "            anomaly_scores = iso_forest.fit_predict(infra_features)\n",
            "            infra_risk = (anomaly_scores == -1).astype(float)\n",
            "        else:\n",
            "            infra_risk = pd.Series(0.1, index=df.index)\n",
            "            \n",
            "        return infra_risk\n",
            "    \n",
            "    def calculate_comprehensive_risk_score(self, df):\n",
            "        \"\"\"Calculate comprehensive risk score\"\"\"\n",
            "        geo_risk = self.calculate_geographic_risk(df)\n",
            "        mode_risk = self.calculate_mode_risk(df)\n",
            "        volatility_risk = self.calculate_volatility_risk(df)\n",
            "        infra_risk = self.calculate_infrastructure_risk(df)\n",
            "        \n",
            "        weights = {'geographic': 0.3, 'mode': 0.25, 'volatility': 0.25, 'infrastructure': 0.2}\n",
            "        \n",
            "        comprehensive_risk = (\n",
            "            geo_risk * weights['geographic'] +\n",
            "            mode_risk * weights['mode'] +\n",
            "            volatility_risk * weights['volatility'] +\n",
            "            infra_risk * weights['infrastructure']\n",
            "        )\n",
            "        \n",
            "        return comprehensive_risk\n",
            "\n",
            "# Apply risk scoring to international data\n",
            "if 'international_df' in locals() and len(international_df) > 0:\n",
            "    try:\n",
            "        risk_scorer = SupplyChainRiskScorer()\n",
            "        risk_scores = risk_scorer.calculate_comprehensive_risk_score(international_df)\n",
            "        international_df['comprehensive_risk_score'] = risk_scores\n",
            "        \n",
            "        print(f\"‚úÖ Risk scores calculated for {len(international_df)} corridors\")\n",
            "        print(f\"   ‚Ä¢ Average Risk Score: {risk_scores.mean():.3f}\")\n",
            "        print(f\"   ‚Ä¢ High-Risk Corridors (>0.7): {len(risk_scores[risk_scores > 0.7]):,}\")\n",
            "        \n",
            "    except Exception as e:\n",
            "        print(f\"‚ùå Risk scoring failed: {e}\")\n",
            "\n",
            "# ============================================================================\n",
            "# 2. PREDICTIVE ANALYTICS IMPLEMENTATION\n",
            "# ============================================================================\n",
            "\n",
            "print(\"\\nü§ñ IMPLEMENTING PREDICTIVE ANALYTICS\")\n",
            "print(\"=\" * 50)\n",
            "\n",
            "class SupplyChainPredictor:\n",
            "    \"\"\"Predictive analytics for supply chain disruptions\"\"\"\n",
            "    \n",
            "    def __init__(self):\n",
            "        self.models = {}\n",
            "        \n",
            "    def prepare_features(self, df):\n",
            "        \"\"\"Prepare features for ML models\"\"\"\n",
            "        features = df[['tons_2023', 'value_2023', 'tmiles_2023', 'trade_type']].copy()\n",
            "        features['tons_per_mile'] = df['tons_2023'] / (df['tmiles_2023'] + 1)\n",
            "        features['value_per_mile'] = df['value_2023'] / (df['tmiles_2023'] + 1)\n",
            "        features['value_per_ton'] = df['value_2023'] / (df['tons_2023'] + 1)\n",
            "        features['efficiency_ratio'] = df['tons_2023'] / (df['tmiles_2023'] + 1)\n",
            "        \n",
            "        # Add geographic features\n",
            "        features['origin_region'] = df['fr_orig']\n",
            "        features['destination_region'] = df['fr_dest']\n",
            "        \n",
            "        # Encode categorical variables\n",
            "        le = LabelEncoder()\n",
            "        features['origin_encoded'] = le.fit_transform(features['origin_region'].astype(str))\n",
            "        features['destination_encoded'] = le.fit_transform(features['destination_region'].astype(str))\n",
            "        \n",
            "        # Remove original categorical columns\n",
            "        features = features.drop(columns=['origin_region', 'destination_region'])\n",
            "        \n",
            "        return features.fillna(0)\n",
            "    \n",
            "    def build_disruption_model(self, df):\n",
            "        \"\"\"Build disruption prediction model\"\"\"\n",
            "        X = self.prepare_features(df)\n",
            "        \n",
            "        # Create disruption target (high volatility = potential disruption)\n",
            "        if 'comprehensive_risk_score' in df.columns:\n",
            "            disruption_threshold = df['comprehensive_risk_score'].quantile(0.8)\n",
            "            y_disruption = (df['comprehensive_risk_score'] > disruption_threshold).astype(int)\n",
            "        else:\n",
            "            efficiency_threshold = X['efficiency_ratio'].quantile(0.2)\n",
            "            y_disruption = (X['efficiency_ratio'] < efficiency_threshold).astype(int)\n",
            "        \n",
            "        # Split data\n",
            "        X_train, X_test, y_train, y_test = train_test_split(X, y_disruption, test_size=0.2, random_state=42)\n",
            "        \n",
            "        # Train Random Forest model\n",
            "        rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
            "        rf_model.fit(X_train, y_train)\n",
            "        \n",
            "        # Evaluate model\n",
            "        score = rf_model.score(X_test, y_test)\n",
            "        \n",
            "        self.models['disruption'] = rf_model\n",
            "        return rf_model, score\n",
            "    \n",
            "    def build_cost_model(self, df):\n",
            "        \"\"\"Build cost prediction model\"\"\"\n",
            "        X = self.prepare_features(df)\n",
            "        y_cost = X['value_per_ton']\n",
            "        X_cost = X.drop(columns=['value_per_ton'])\n",
            "        \n",
            "        # Split data\n",
            "        X_train, X_test, y_train, y_test = train_test_split(X_cost, y_cost, test_size=0.2, random_state=42)\n",
            "        \n",
            "        # Train model\n",
            "        rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
            "        rf_model.fit(X_train, y_train)\n",
            "        \n",
            "        # Evaluate model\n",
            "        y_pred = rf_model.predict(X_test)\n",
            "        r2 = r2_score(y_test, y_pred)\n",
            "        \n",
            "        self.models['cost'] = rf_model\n",
            "        return rf_model, r2\n",
            "    \n",
            "    def generate_predictions(self, df):\n",
            "        \"\"\"Generate predictions for all models\"\"\"\n",
            "        X = self.prepare_features(df)\n",
            "        predictions = {}\n",
            "        \n",
            "        for model_name, model in self.models.items():\n",
            "            try:\n",
            "                if hasattr(model, 'predict_proba'):\n",
            "                    pred_proba = model.predict_proba(X)\n",
            "                    predictions[f'{model_name}_probability'] = pred_proba[:, 1]\n",
            "                    predictions[f'{model_name}_prediction'] = model.predict(X)\n",
            "                else:\n",
            "                    predictions[f'{model_name}_prediction'] = model.predict(X)\n",
            "            except Exception as e:\n",
            "                print(f\"Warning: {model_name} prediction failed: {e}\")\n",
            "        \n",
            "        return predictions\n",
            "\n",
            "# Apply predictive analytics to international data\n",
            "if 'international_df' in locals() and len(international_df) > 0:\n",
            "    try:\n",
            "        predictor = SupplyChainPredictor()\n",
            "        \n",
            "        # Build models\n",
            "        disruption_model, disruption_score = predictor.build_disruption_model(international_df)\n",
            "        cost_model, cost_r2 = predictor.build_cost_model(international_df)\n",
            "        \n",
            "        # Generate predictions\n",
            "        predictions = predictor.generate_predictions(international_df)\n",
            "        \n",
            "        # Add predictions to dataframe\n",
            "        for pred_name, pred_values in predictions.items():\n",
            "            international_df[pred_name] = pred_values\n",
            "        \n",
            "        print(f\"‚úÖ Predictive models trained successfully\")\n",
            "        print(f\"   ‚Ä¢ Disruption Prediction Accuracy: {disruption_score:.3f}\")\n",
            "        print(f\"   ‚Ä¢ Cost Prediction R¬≤: {cost_r2:.3f}\")\n",
            "        \n",
            "    except Exception as e:\n",
            "        print(f\"‚ùå Predictive analytics failed: {e}\")\n",
            "\n",
            "# ============================================================================\n",
            "# 3. EXECUTIVE DASHBOARD CREATION\n",
            "# ============================================================================\n",
            "\n",
            "print(\"\\nüìä CREATING EXECUTIVE DASHBOARD\")\n",
            "print(\"=\" * 40)\n",
            "\n",
            "class ExecutiveDashboard:\n",
            "    \"\"\"Executive dashboard for supply chain insights\"\"\"\n",
            "    \n",
            "    def calculate_health_score(self, df):\n",
            "        \"\"\"Calculate supply chain health score\"\"\"\n",
            "        efficiency_score = (df['tons_2023'] / (df['tmiles_2023'] + 1)).mean()\n",
            "        value_density = (df['value_2023'] / (df['tons_2023'] + 1)).mean()\n",
            "        \n",
            "        risk_adjustment = 0\n",
            "        if 'comprehensive_risk_score' in df.columns:\n",
            "            risk_adjustment = df['comprehensive_risk_score'].mean()\n",
            "        \n",
            "        health_score = (efficiency_score * 0.4 + value_density * 0.3 + (1 - risk_adjustment) * 0.3) * 100\n",
            "        health_score = max(0, min(100, health_score))\n",
            "        \n",
            "        return health_score\n",
            "    \n",
            "    def generate_recommendations(self, df):\n",
            "        \"\"\"Generate strategic recommendations\"\"\"\n",
            "        recommendations = []\n",
            "        \n",
            "        health_score = self.calculate_health_score(df)\n",
            "        \n",
            "        if health_score < 60:\n",
            "            recommendations.append({\n",
            "                'category': 'Health Improvement',\n",
            "                'priority': 'High',\n",
            "                'recommendation': 'Implement efficiency optimization programs',\n",
            "                'expected_impact': 'Increase health score by 15-20 points'\n",
            "            })\n",
            "        \n",
            "        if 'comprehensive_risk_score' in df.columns:\n",
            "            high_risk_count = len(df[df['comprehensive_risk_score'] > 0.7])\n",
            "            if high_risk_count > 0:\n",
            "                recommendations.append({\n",
            "                    'category': 'Risk Mitigation',\n",
            "                    'priority': 'High',\n",
            "                    'recommendation': f'Address {high_risk_count} high-risk corridors',\n",
            "                    'expected_impact': 'Reduce risk exposure by 25-30%'\n",
            "                })\n",
            "        \n",
            "        return recommendations\n",
            "\n",
            "# Create executive dashboard\n",
            "if 'international_df' in locals() and len(international_df) > 0:\n",
            "    try:\n",
            "        dashboard = ExecutiveDashboard()\n",
            "        health_score = dashboard.calculate_health_score(international_df)\n",
            "        recommendations = dashboard.generate_recommendations(international_df)\n",
            "        \n",
            "        print(f\"‚úÖ Executive dashboard created\")\n",
            "        print(f\"   ‚Ä¢ Supply Chain Health Score: {health_score:.1f}/100\")\n",
            "        print(f\"   ‚Ä¢ Strategic Recommendations: {len(recommendations)}\")\n",
            "        \n",
            "        # Display recommendations\n",
            "        print(\"\\nüí° STRATEGIC RECOMMENDATIONS:\")\n",
            "        for i, rec in enumerate(recommendations, 1):\n",
            "            print(f\"   {i}. {rec['category']} ({rec['priority']} Priority)\")\n",
            "            print(f\"      {rec['recommendation']}\")\n",
            "            print(f\"      Expected Impact: {rec['expected_impact']}\")\n",
            "        \n",
            "    except Exception as e:\n",
            "        print(f\"‚ùå Executive dashboard failed: {e}\")\n",
            "\n",
            "# ============================================================================\n",
            "# 4. ADVANCED VISUALIZATIONS\n",
            "# ============================================================================\n",
            "\n",
            "print(\"\\nüìà CREATING ADVANCED VISUALIZATIONS\")\n",
            "print(\"=\" * 40)\n",
            "\n",
            "# Create risk distribution visualization\n",
            "if 'international_df' in locals() and len(international_df) > 0:\n",
            "    try:\n",
            "        if 'comprehensive_risk_score' in international_df.columns:\n",
            "            plt.figure(figsize=(15, 10))\n",
            "            \n",
            "            # Risk distribution\n",
            "            plt.subplot(2, 3, 1)\n",
            "            plt.hist(international_df['comprehensive_risk_score'], bins=30, alpha=0.7, color='red', edgecolor='black')\n",
            "            plt.title('Risk Score Distribution')\n",
            "            plt.xlabel('Risk Score')\n",
            "            plt.ylabel('Frequency')\n",
            "            \n",
            "            # Risk by region\n",
            "            plt.subplot(2, 3, 2)\n",
            "            risk_by_region = international_df.groupby('fr_orig')['comprehensive_risk_score'].mean().sort_values(ascending=False)\n",
            "            plt.bar(range(len(risk_by_region)), risk_by_region.values, color='orange')\n",
            "            plt.title('Average Risk by Region')\n",
            "            plt.xlabel('Region')\n",
            "            plt.ylabel('Average Risk Score')\n",
            "            \n",
            "            # Efficiency vs Risk\n",
            "            plt.subplot(2, 3, 3)\n",
            "            efficiency = international_df['tons_2023'] / (international_df['tmiles_2023'] + 1)\n",
            "            plt.scatter(efficiency, international_df['comprehensive_risk_score'], alpha=0.6, c=international_df['value_2023'], cmap='viridis')\n",
            "            plt.colorbar(label='Value ($)')\n",
            "            plt.title('Efficiency vs Risk Score')\n",
            "            plt.xlabel('Efficiency Ratio')\n",
            "            plt.ylabel('Risk Score')\n",
            "            \n",
            "            # Prediction visualizations\n",
            "            prediction_cols = [col for col in international_df.columns if 'prediction' in col or 'probability' in col]\n",
            "            if prediction_cols:\n",
            "                for i, col in enumerate(prediction_cols[:3], 4):\n",
            "                    plt.subplot(2, 3, i)\n",
            "                    plt.hist(international_df[col].dropna(), bins=20, alpha=0.7, edgecolor='black')\n",
            "                    plt.title(f'{col.replace(\"_\", \" \").title()}')\n",
            "                    plt.xlabel('Prediction Value')\n",
            "                    plt.ylabel('Frequency')\n",
            "            \n",
            "            plt.tight_layout()\n",
            "            plt.show()\n",
            "            \n",
            "            print(\"‚úÖ Advanced visualizations created successfully\")\n",
            "            \n",
            "    except Exception as e:\n",
            "        print(f\"‚ùå Advanced visualizations failed: {e}\")\n",
            "\n",
            "print(\"\\n‚úÖ MACHINE LEARNING ENHANCEMENTS COMPLETED SUCCESSFULLY!\")\n",
            "print(\"=\" * 60)\n"
        ]
    }
    
    # Create a markdown cell with summary
    summary_cell = {
        "cell_type": "markdown",
        "metadata": {},
        "source": [
            "# ü§ñ Machine Learning Enhancements Summary\n",
            "\n",
            "## üéØ What Was Added:\n",
            "\n",
            "### 1. **Risk Scoring System**\n",
            "- Comprehensive risk scores for all supply chain corridors\n",
            "- Multi-dimensional risk assessment (geographic, mode, volatility, infrastructure)\n",
            "- High-risk corridor identification\n",
            "\n",
            "### 2. **Predictive Analytics**\n",
            "- Disruption prediction models\n",
            "- Cost forecasting capabilities\n",
            "- Machine learning models with performance metrics\n",
            "\n",
            "### 3. **Executive Dashboard**\n",
            "- Supply chain health scoring (0-100)\n",
            "- Strategic recommendations based on ML insights\n",
            "- Actionable business intelligence\n",
            "\n",
            "### 4. **Advanced Visualizations**\n",
            "- Risk distribution analysis\n",
            "- Prediction model outputs\n",
            "- Interactive charts and graphs\n",
            "\n",
            "## üìä Key Metrics Available:\n",
            "- **Risk Scores**: 0-1 scale for each corridor\n",
            "- **Health Score**: Overall supply chain health (0-100)\n",
            "- **Prediction Accuracy**: Model performance metrics\n",
            "- **Strategic Recommendations**: Actionable insights\n",
            "\n",
            "## üöÄ Next Steps:\n",
            "1. Review the risk scores and identify high-risk corridors\n",
            "2. Analyze prediction model outputs for strategic planning\n",
            "3. Implement recommendations based on executive dashboard\n",
            "4. Monitor key metrics for continuous improvement\n"
        ]
    }
    
    # Find the last cell in the notebook
    last_cell_index = len(notebook['cells']) - 1
    
    # Insert the ML enhancement cell before the last cell
    notebook['cells'].insert(last_cell_index, ml_enhancement_cell)
    notebook['cells'].insert(last_cell_index + 1, summary_cell)
    
    # Save the modified notebook
    try:
        with open('Supply_Chain_Volatility_Intl.ipynb', 'w', encoding='utf-8') as f:
            json.dump(notebook, f, indent=1, ensure_ascii=False)
        print("‚úÖ Successfully integrated ML enhancements into notebook")
        print("üìÅ Modified: Supply_Chain_Volatility_Intl.ipynb")
        return True
    except Exception as e:
        print(f"‚ùå Error saving notebook: {e}")
        return False

if __name__ == "__main__":
    success = integrate_ml_enhancements_into_notebook()
    if success:
        print("\nüéâ INTEGRATION COMPLETE!")
        print("\nüìã Next Steps:")
        print("1. Open Supply_Chain_Volatility_Intl.ipynb in Jupyter")
        print("2. Run all cells to execute the ML enhancements")
        print("3. Review the new ML analysis results")
        print("4. Use the insights for strategic decision-making")
    else:
        print("\n‚ùå Integration failed. Please check the error messages above.") 